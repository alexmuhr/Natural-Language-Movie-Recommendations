'''
RECOMMENDATIONS

This file contains functions to search an input text for names of actors, genres, and movies, then uses the entity_sentiment library
to determine sentiment towards each one. This sentiment information is then used to generate a movie recommendation. Finally the recommendation
is presented in a natural conversational format.

In order to execute the above tasks, pickle files generated by movies_dataset_engineering.ipynb are loaded. These provide information on
movies actors and genres.
'''


import pandas as pd
import pickle
from copy import copy
import numpy as np
import random


import entity_sentiment

actors = pickle.load(open('pickles/actor_list.pkl', 'rb'))
movies = pickle.load(open('pickles/movie_list.pkl', 'rb'))
genres = pickle.load(open('pickles/genre_list.pkl', 'rb'))
movie_array = pickle.load(open('pickles/movie_array.pkl', 'rb'))
norms = pickle.load(open('pickles/norms.pkl', 'rb'))
col_names = pickle.load(open('pickles/col_names.pkl', 'rb'))
movie_names = pickle.load(open('pickles/movie_names.pkl', 'rb'))
movie_metadata = pickle.load(open('pickles/movie_metadata.pkl', 'rb'))




def find_entities(text, actors = actors, movies = movies, genres = genres):
    '''
    Takes as input a sentence. Return a dictionary containing two keys, text and entities.
    text is the original text with named entities concatenated with dashes (assuming they are more than one word).
    entities is a list of the entities contained in the text.
    '''
    output_text = copy(text)

    entities = []

    for actor in actors:
        if text.find(actor) != -1:
            output_text = output_text.replace(actor, '-'.join(actor.split(' ')))
            entities.append(('-'.join(actor.split(' ')), 'A'))

    for movie in movies:
        if text.find(movie) != -1:
            output_text = output_text.replace(movie, '-'.join(movie.split(' ')))
            entities.append(('-'.join(movie.split(' ')), 'M'))

    # Make lower case for genre search
    output_text = output_text.lower()
    for genre in genres:
        if text.lower().find(genre) != -1:
            output_text.replace(genre, '-'.join(genre.split(' ')))
            entities.append(('-'.join(genre.split(' ')), 'G'))

    return {'original_text': text, 'text': output_text, 'entities': entities}




def find_entity_sentiments(text, actors = actors, movies = movies, genres = genres):
    '''
    Finds actors and movie titles in sentence, then find sentiment towards each one.
    Return a dictionary with text, entities, and sentiment towards each entity
    '''
    # Split text into sentences
    sentences = text.split('.')
    for i, sent in enumerate(sentences):
        if sent == '':
            sentences.pop(i)

    # Find entities in each sentence. Determine sentiment for each entity.
    # Store all this info in a dictionary.
    sent_dicts = []
    for sent in sentences:
        # At first we do not have a DependencyTreeDict object (defines dep tree) for each sentence
        tree_dict = False
        if len(sent) > 0:
            sent_dict = find_entities(sent, actors = actors, movies = movies, genres = genres)
            for entity in sent_dict['entities']:
                # If we don't have a tree_dict then we need to build one
                if tree_dict == False:
                    sent_dict[entity], tree_dict = entity_sentiment.compile_ensemble_sentiment(sent_dict['text'], entity[0])
                # If tree_dict already exists don't waste time building another
                else:
                    sent_dict[entity], tree_dict = entity_sentiment.compile_ensemble_sentiment(sent_dict['text'], entity[0], tree_dict = tree_dict)
        sent_dicts.append(sent_dict)

    # Compile results for each sentence
    output_dict = {}
    output_dict['original_text'] = text

    # Compile text with concatenated entities
    output_text = []
    for sent_dict in sent_dicts:
        output_text.append(sent_dict['text'])
    output_dict['text'] = '. '.join(output_text) + '.'

    # Compile a list of entities
    entities = []
    for sent_dict in sent_dicts:
        entities += sent_dict['entities']
    output_dict['entities'] = list(set(entities))

    # Compile sentiment for each entity
    for entity in output_dict['entities']:
        sentiment = {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound': 0.0}
        count = 0
        # Iterate through sentences to find those which contain the entity
        for sent_dict in sent_dicts:
            if entity in sent_dict['entities']:
                count += 1
                # Aggregate sentiment
                for key in sentiment.keys():
                    sentiment[key] += sent_dict[entity][key]
        # Divide by count to get average
        for key in sentiment.keys():
            sentiment[key] = sentiment[key] / count

        output_dict[entity[0]] = sentiment

    return output_dict





def generate_feature_vector(sentiments, movie_array = movie_array, movie_names = movie_names, col_names = col_names):
    '''
    Generates a feature vector for comparison against movie database. Feature vector is determined by sentiment
    towards entities. Input is output of find_entity_sentiments.
    '''

    feat_vec = np.zeros(20)

    for entity in sentiments['entities']:
        # Find the name and net sentiment of the entity
        entity_name = ' '.join(entity[0].split('-')).lower()
        net_sent = sentiments[entity[0]]['pos'] - sentiments[entity[0]]['neg']

        # If the entity is a movie use the movie's feature vector
        if entity[1] == 'M':
            feat_vec += net_sent * movie_array[movie_names.index(entity_name),:20]
            # Add in a bit of randomness
            rand_vec = np.random.rand(20)
            rand_vec = rand_vec / (np.sum(rand_vec)*5)
            rand_vec = rand_vec - np.sum(rand_vec) / 20
            feat_vec += rand_vec

    # If no movies mentioned just make the feature vector random
    if np.sum(feat_vec) == 0:
        feat_vec = np.random.rand(20,)

    return feat_vec





def produce_rec(sentiments, movie_array = movie_array, movie_names = movie_names, col_names = col_names, movie_metadata = movie_metadata,
                norms = norms):
    '''
    Takes a feature vector as input. Uses numpy to compute cosign distance between feature vector
    and every movie. Returns metadata for the movie.
    '''
    feat_vec = generate_feature_vector(sentiments, movie_array = movie_array, movie_names = movie_names, col_names = col_names)


    # create copy of movie_array
    feat_array = copy(movie_array[:,:20])

    for entity in sentiments['entities']:
        entity_name = ' '.join(entity[0].split('-')).lower()

        # set rows for movies mentioned in text to 0. This prevents recommending mentioned movies.
        if entity[1] == 'M':
            row_ix = movie_names.index(entity_name)
            feat_array[row_ix,:] = 0

        # filter outputs based on genres and actors
        if entity[1] == 'G' or entity[1] == 'A':
            net_sent = sentiments[entity[0]]['pos'] - sentiments[entity[0]]['neg']
            # if sentiment towards genre is very high, then filter to only movies of genre
            if net_sent > 0.5:
                row_ix = np.where(movie_array[:,col_names.index(entity_name)] == 0)
                for ix in row_ix:
                    feat_array[ix,:] = 0
            # if sentiment towards genre is negative, then filter out movies of genre
            if net_sent < 0.25:
                row_ix = np.where(movie_array[:, col_names.index(entity_name)] == 1)
                for ix in row_ix:
                    feat_array[ix,:] = 0

    # If somehow all movies have been eliminated by actor / genre filtering, set feat array back to a
    # copy of movie_array. Essentially don't take into account any actor / genre filtering.
    if np.sum(feat_array) == 0:
        feat_array = copy(movie_array[:,:20])
        print('Everything filtered to zero!')

    # Compute cosine similarities and pick the max
    dots = np.matmul(feat_array, feat_vec)
    input_norm = np.linalg.norm(feat_vec)
    co_dists = dots / (input_norm * norms)

    return movie_metadata.loc[np.argmax(co_dists)]





def generate_response(rec, sentiments):
    # beginning of response
    response = "Hi there, "

    # determine things that were liked and disliked
    likes = []
    dislikes = []
    fav_actors = []
    title = rec['title']
    genres = ', '.join(rec['genres'])
    year = rec['release_date'].split('-')[0]

    # find things that were liked vs disliked
    for entity in sentiments['entities']:
        net_sent = sentiments[entity[0]]['pos'] - sentiments[entity[0]]['neg']
        entity_name = ' '.join(entity[0].split('-'))
        if net_sent > 0.25:
            likes.append(entity_name)
        if net_sent < 0.25:
            dislikes.append(entity_name)
        # find actors that were strongly liked
        if entity[1] == 'A' and net_sent > 0.5:
            if entity_name in rec['cast_list']:
                fav_actors.append(entity_name)

    # mention things that user likes
    if len(likes) > 0:
        if len(likes) == 1:
            response += f"I see you like {likes[0]}. "
        if len(likes) == 2:
            response += f"I see you like {likes[0]} and {likes[1]}. "
        if len(likes) >= 3:
            response += "I see you like " + ", ".join(likes[:-1])
            response += f", and {likes[-1]}. "

    # mention things that user dislikes
    if len(dislikes) > 0:
        if len(likes) > 0:
            response += "I also "
        else:
            response += "I "
        if len(dislikes) == 1:
            response += f"see that you don't like {dislikes[0]}. "
        if len(dislikes) == 2:
            response += f"see that you don't like {dislikes[0]} and {dislikes[1]}. "
        if len(dislikes) >= 3:
            response += "see that you don't " + ", ".join(dislikes[:-1])
            response += f", and {dislikes[-1]}. "

    # recommend movie
    response += f"Based on your preferences, I really think you'll enjoy the movie {title}, a {genres} movie from {year}"

    if len(fav_actors) == 0:
        response += "."

    else:
        if len(fav_actors) == 1:
            response += f" featuring {fav_actors[0]}."
        if len(fav_actors) == 2:
            response += f" featuring {fav_actors[0]} and {fav_actors[1]}."
        if len(fav_actors) >= 3:
            response += "featuring " + ", ".join(fav_actors[:-1])
            response += f", and {fav_actors[-1]}."

    return response





def full_rec_pipeline(text, movie_array = movie_array, actors = actors, movies = movies, genres = genres, movie_names = movie_names,
                      col_names = col_names, movie_metadata = movie_metadata, norms = norms):
    '''
    Input is a user written passage about movies, actors, and genres that they do or don't like.
    Output is metadata for a movie recommendation.
    '''

    sentiments = find_entity_sentiments(text, actors = actors, movies = movies, genres = genres)
    rec = produce_rec(sentiments, movie_array = movie_array, movie_names = movie_names, col_names = col_names, movie_metadata = movie_metadata,
                      norms = norms)

    return generate_response(rec, sentiments)
